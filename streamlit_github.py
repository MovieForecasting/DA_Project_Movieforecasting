import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
from io import StringIO
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
import joblib
import requests
import io
# Base URL for GitHub raw files
github_base_url = "https://raw.githubusercontent.com/MovieForecasting/DA_Project_Movieforecasting/main/"
from sklearn.metrics import r2_score

st.set_page_config(page_title="Pr√©vision du succ√®s d'un film", page_icon="üé•")
st.markdown(
    """
    <style>
    /* Fond statique tr√®s clair */
    [data-testid="stAppViewContainer"] {
    background-color: #f7f7f7 !important;
    }
    
    /* Import de la police Orbitron pour un rendu futuriste */
    @import url('https://fonts.googleapis.com/css2?family=Orbitron:wght@400;700&display=swap');
    
    .stApp {
        font-family: 'Orbitron', sans-serif;
    }
    
    /* Barre lat√©rale (banni√®re de c√¥t√©) */
    [data-testid="stSidebar"] {
        background: #eef3f7 !important;
        color: #333333 !important;
        border-right: 1px solid #d0d7de;
    }
    
    /* Header : d√©grad√© inspir√© de la couleur de la sidebar */
    header {
        background: linear-gradient(180deg, #eef3f7, #dce4eb) !important;
        color: #333333 !important;
        border-bottom: 1px solid #d0d7de;
    }
    
    /* Zone principale */
    .main .block-container {
        background: #ffffff !important;
        border-radius: 12px;
        padding: 2rem;
        margin: 1rem auto;
        max-width: 1200px;
        box-shadow: 0 6px 12px rgba(0,0,0,0.1);
    }
    
    /* Boutons : style moderne en utilisant la couleur de la sidebar comme r√©f√©rence */
    div.stButton > button, div.stForm > button {
        transition: transform 0.3s ease, background 0.3s ease, box-shadow 0.3s ease;
        background: linear-gradient(180deg, #eef3f7, #dce4eb);
        color: #333333;
        border: none;
        border-radius: 6px;
        padding: 0.6rem 1.4rem;
        box-shadow: 0 3px 6px rgba(0,0,0,0.1);
        font-weight: 600;
    }
    
    div.stButton > button:hover, div.stForm > button:hover {
        transform: scale(1.05);
        background: linear-gradient(180deg, #dce4eb, #bcc4cd);
        box-shadow: 0 6px 12px rgba(0,0,0,0.2);
        color: #333333;
    }
    
    /* Style pour les liens */
    a {
        color: #0077b6;
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    </style>
    """,
    unsafe_allow_html=True
)

df_exploration = pd.read_csv(github_base_url + "df_github.csv")

buffer = StringIO()
df_exploration.info(buf=buffer)
s = buffer.getvalue()

# Transformation du dataframe pour Exploration du Dataset
df_exploration['release_date'] = pd.to_datetime(df_exploration['release_date'], errors='coerce')
df_until_2023 = df_exploration[df_exploration['release_date'].dt.year <= 2023].copy()
df_until_2023_sorted = df_until_2023.sort_values(by='popularity', ascending=False)

st.title("Pr√©vision du succ√®s d'un film")

image_path = "logo_datascientest.png"
st.sidebar.image(image_path, width=180)

st.sidebar.title("Sommaire")

import streamlit.components.v1 as components
music_url = github_base_url + "Time.mp3"
components.html(
    f"""
    <audio src="{music_url}" autoplay loop muted controls>
      Your browser does not support the audio element.
    </audio>
    """,
    height=0
)

pages=["Pr√©sentation du projet üöÄ", "Exploration du Dataset üßê", "DataViz' üìä", "Pr√©-processing üë®‚Äçüíª", "Mod√©lisation / Machine Learning ‚öôÔ∏è", "Application üé•", "Conclusion üé¨"]

page=st.sidebar.radio("Aller vers", pages)

st.sidebar.write("__Auteurs__")

st.sidebar.write("[Camille Laluque](https://www.linkedin.com/in/camille-cadet-51629b140/)")
st.sidebar.markdown("[Samy Cao](https://www.linkedin.com/in/samy-cao)")
st.sidebar.write("[Jean-No√´l Duchevet](https://www.linkedin.com/in/jean-noel-duchevet/)")
st.sidebar.write("[Tristan Tansu](https://www.linkedin.com/in/tristan-tansu-42009365/)")

st.sidebar.write("Promotion Data Analyst : Janvier 2025")

if page == pages[0]:
    image_path = "image_sommaire.png"
    st.image(image_path, width=700)
    st.write("### Pr√©sentation du projet")
    st.write("Ce projet a √©t√© r√©alis√© dans le cadre de notre formation en Data Analyse via l'organisme Data Scientest.")
    st.write("L'objectif de ce projet est de pr√©dire le succ√®s d'un film au box-office en utilisant le jeu de donn√©e issu de TMDB : 'The Movie DataBase' o√π nous pouvons obtenir des informations comme le budget, les recettes, le genre, les acteurs et les r√©alisateurs.")
    st.write("Gr√¢ce √† l‚Äôanalyse de ces donn√©es, nous pouvons mieux comprendre lesquelles ont une influence dans le succ√®s d'un film.")
  
    st.write("### Probl√©matique")
  
    st.write("Quels sont les √©l√©ments cl√©s qui influencent le succ√®s d‚Äôun film ? Peut-on pr√©dire ce succ√®s √† partir des donn√©es disponibles ?")

elif page == pages[1]:
    
    st.write("### Exploration du Dataset")
    image_path = "image_exploration.png"
    st.image(image_path, width=700)

    st.write("Ci-dessous un aper√ßu du dataset :")
    st.dataframe(df_exploration.head())
    
    st.write("Dimensions du dataframe :")
    
    st.write(df_exploration.shape)

    st.write("Autres informations sur le dataframe :")

    with st.expander("Informations sur le dataset"):
        st.text(s)

    if st.checkbox("Montrer les valeurs manquantes"): 
        missing_df = df_exploration.isna().sum().reset_index()
        missing_df.columns = ["Colonne", "Nombre de NaN"]
        missing_df["Pourcentage (%)"] = (missing_df["Nombre de NaN"] / len(df_exploration)) * 100
        missing_df = missing_df.sort_values(by="Pourcentage (%)", ascending=False)
        st.table(missing_df)
    
    if st.checkbox("Montrer les doublons") : 
        st.write(df_exploration.duplicated().sum())

elif page == pages[2]:

    st.write("Nous allons ensuite pr√©senter divers graphiques exploitant nos jeux de donn√©es.")

    st.write("### M√©thodologie")

    st.write("#### Variable 'Popularity'")

    st.write("Nous nous int√©ressons √† l'indicateur 'popularity' de TMDB (The Movie Database) qui sera la variable d'analyse exploratoire car il refl√®te la popularit√© d'un film ou d'une s√©rie selon plusieurs crit√®res. L'algorithme de calcul de cet indicateur n'est pas public mais nous savons qu'il est bas√© sur plusieurs facteurs :")
    st.write("""
    - Les vues des pages
    - Les votes des utilisateurs
    - Le nombre d'ajout en 'favoris' et/ou en 'watchlist'
    - Le nombre de recherches sur la plateforme
    - Les mentions sur les r√©seaux
    - Les ann√©es de lancement
    - Le 'popularity score' du jour pr√©c√©dent
             """)
    st.write("L'indicateur de popularit√© refl√®te un caract√®re dynamique. Il peut fluctuer en fonction des tendances actuelles, des sorties r√©centes, ou de l'impact viral sur les plateformes sociales gr√¢ce √† l'interactions des utilisateurs. Plus un film ou une s√©rie est mentionn√© et/ou recherch√©, plus sa popularit√© sera √©lev√©e sur TMDB.")

    st.markdown("[Source TMDB](https://developer.themoviedb.org/docs/popularity-and-trending)")
    st.write("Notre premi√®re approche sur cet indicateur a √©t√© de montrer son √©volution moyenne au fil des ann√©es c'est √† dire de 1980 √† 2025 soit sur l'ensemble des donn√©es de notre dataset.")

    st.write("Rapidement nous nous sommes rendu compte que l'ann√©e 2024 pr√©sente des valeurs extr√™mes de popularit√©. En effet, comme expliqu√© pr√©c√©dement cet indicateur pr√©sente un caract√®re dynamique du fait qu'il est mis √† jour r√©guli√®rement en fonction des param√®tres qui le composent.")

    st.write("##### Avis 'm√©tier'")

    st.write("A titre d'exemple, nous pouvons penser que les films sorti en 2024 dans notre dataset dont certains qui l'ont √©t√© r√©cemment notamment sur le mois de d√©cembre, ont un score √©lev√© de popularit√© car ils suscitent beaucoup d'int√©r√™t et de curiostit√© de la part des utilisateurs. Cela rev√™t donc une importance dans l'analyse de donn√©es temporelles.")
    st.write("Afin de limiter l'impact de ces valeurs sur nos analyses, nous d√©cidons d'exclure les donn√©es relatives √† 2024.")

    st.write("##### Conclusion & Exploitation")

    st.write("Ce travail d'exploration va s'articuler autour de la variable 'popularity' notamment sa saisonalit√© et son interaction avec diff√©rentes variables telles que le genre, le budget, les r√©alisateurs et les acteurs.")
    
    image_path = "boxplot_popularity2024.png"
    st.image(image_path, width=600)

    with st.expander("Cr√©ation de la variable 'Weighted Rating"):
        st.write("#### Weighted Rating : Qu‚Äôest-ce que c‚Äôest ?")
        st.write("Le weighted rating (ou note pond√©r√©e) est une mesure qui vise √† mieux refl√©ter la qualit√© d‚Äôun film qu‚Äôune simple note moyenne. En effet, si un film n‚Äôa que 2 votes √† 10/10, il ne doit pas d√©passer un blockbuster ayant 10 000 votes √† 8/10. Le weighted rating corrige ce probl√®me en tenant compte √† la fois de la note moyenne du film et de la note moyenne globale du catalogue, pond√©r√©es par le nombre de votes du film.")
        st.write("##### Analyse de la formule de calcul du Weighted Rating")
        st.code("""
        *C = df['vote_average'].mean()
        *C : la moyenne globale (vote_average) de tous les films.
        *m = df['vote_count'].quantile(0.90)
        *m : un seuil de votes, ici le 90·µâ percentile de vote_count.
        
        Autrement dit, si le film d√©passe ce seuil, il aura plus de poids dans son √©valuation.
        
        Cette formule s‚Äôinspire de l‚Äôalgorithme d‚ÄôIMDb :

        Weighted Rating = (v / (v+m)) * R + (m / (v+m)) * C
        
        o√π :
        *v = nombre de votes pour ce film,
        *R = note moyenne du film (vote_average),
        *C = note moyenne globale,
        *m = seuil minimum de votes.
        """)

        st.write("##### Avis 'm√©tier'")
        st.write("Une fois qu'un film poss√®de un weighted rating, on peut l'associer :")
        st.write("""
        - aux acteurs (actrices) ayant particip√© √† ce film
        - aux r√©alisteurs (r√©alisatrices)
        """)
        st.write("**Filtrage** : On peut imposer des seuils de popularit√© et de weighted rating pour retenir uniquement les acteurs/r√©alisateurs associ√©s √† des films ‚Äúvalid√©s‚Äù par un consensus suffisant.")
        st.write("**Pr√©diction pr√©-sortie*** : Lorsque vous pr√©voyez le succ√®s potentiel d‚Äôun futur film, savoir qu‚Äôun acteur ou r√©alisateur a souvent travaill√© sur des films avec un fort weighted rating peut √™tre un indicateur de qualit√©.")

        st.write("##### Conclusion & Exploitation")
        st.write("Le weighted rating permet de compenser la variable popularity en ajoutant une dimension de fiabilit√© dans l‚Äôappr√©ciation. Si la popularit√© est la ‚Äútemp√©rature‚Äù instantan√©e de l‚Äôint√©r√™t du public, le weighted rating est un ‚Äúthermostat‚Äù plus stable, bas√© sur la quantit√© et la qualit√© des votes.")
        st.write("Cela nous permet d‚Äôobtenir une √©valuation plus repr√©sentative et d‚Äô√©viter que des films avec peu de votes ne faussent les r√©sultats.")
    
    # Cr√©ation de la variable "weighted_rating"
    C = df_until_2023_sorted['vote_average'].mean()
    m = df_until_2023_sorted['vote_count'].quantile(0.90)

    def weighted_rating(row, m=m, C=C):
        v = row['vote_count']
        R = row['vote_average']
        if (v+m) == 0:
            return R
        return (v/(v+m))*R + (m/(v+m))*C

    df_until_2023_sorted['weighted_rating'] = df_until_2023_sorted.apply(weighted_rating, axis=1)
    
    # Ajout d'onglets
    tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs(["DataViz' 1", "DataViz' 2", "DataViz' 3","DataViz' 4","DataViz' 5","DataViz' 6","DataViz' 7"])

    # Ajouter du contenu dans chaque onglet
    with tab1:
        st.title("Evolution de la popularit√© des films au fil des ann√©es")

        avg_popularity = df_until_2023_sorted.groupby('release_year')['popularity'].mean()
        fig2, ax = plt.subplots(figsize=(10, 6))
        ax.plot(avg_popularity.index, avg_popularity.values)
        ax.set_title("Evolution de la popularit√© moyenne des films au fil des ann√©es");
        ax.set_xlabel("Ann√©e")
        ax.set_ylabel("Popularit√©")
        st.pyplot(fig2)
        
        st.write("##### Analyse du graphique")
        st.write("""
        Le graphique montre l‚Äô√©volution de la popularit√© moyenne des films en fonction de leur ann√©e de sortie. Plusieurs tendances √©mergent :
        - **Tendance g√©n√©rale √† la hausse :** On observe une augmentation progressive de la popularit√© des films au fil des d√©cennies. Cette tendance peut √™tre li√©e √† une am√©lioration des techniques de production, √† une meilleure accessibilit√© aux films et √† une augmentation du nombre de spectateurs.
        - **Pics et baisses de popularit√© :** Certaines ann√©es affichent des pics, ce qui pourrait √™tre d√ª √† la sortie de films marquants qui ont domin√© le box-office et influenc√© la tendance g√©n√©rale. La baisse notable en 2020 co√Øncide avec la crise sanitaire mondiale, qui a entra√Æn√© une diminution du nombre de films en salle et une r√©duction du nombre de spectateurs.
        """)

        st.write("##### Avis 'm√©tier'")
        st.write("Cette analyse est pertinente pour comprendre l‚Äô√©volution des attentes du public et l‚Äôimpact des grandes tendances cin√©matographiques.")
        st.write("L'augmentation g√©n√©rale de la popularit√© peut √™tre attribu√©e √† l'√©volution du marketing des films, √† l'essor des grandes franchises, ainsi qu'√† une meilleure structuration des sorties en salle.")
        st.write("Les baisses de certaines p√©riodes peuvent √™tre li√©es √† des crises √©conomiques, √† des changements dans l‚Äôindustrie cin√©matographique ou √† une concurrence accrue entre les films.")
        st.write("L‚Äô√©tude de ces variations permet aux producteurs et distributeurs de mieux anticiper le march√© et d‚Äôadapter leurs strat√©gies de sortie.")

        st.write("##### Conclusion & Exploitation")
        st.write("Si l‚Äôann√©e de sortie influence la popularit√©, elle pourrait √™tre int√©gr√©e comme une variable cl√© dans notre mod√®le de pr√©diction du succ√®s au box-office.. Apr√®s lecture du graphique, on remarque une stabilisation √† partir de 1995, il nous semble utile de r√©duite notre jeu de donn√©es de films √† partir cette ann√©e.")

    with tab2:
        st.title("Popularit√© moyenne des films en fonction du mois de sortie")

        if 'release_month' not in df_until_2023_sorted.columns:
            df_until_2023_sorted['release_month'] = df_until_2023_sorted['release_date'].dt.month
        
        pop_by_month = df_until_2023_sorted.groupby('release_month')['popularity'].mean()

        fig3, ax = plt.subplots(figsize=(10,6))
        ax.plot(pop_by_month.index, pop_by_month.values, marker='o', linestyle='-', color='orange')
        ax.set_title("Popularit√© moyenne des films par mois de sortie");
        ax.set_xlabel("Mois")
        ax.set_ylabel("Popularit√© moyenne")

        # Mettre en avant les mois cl√©s
        highlight_months = [7, 12]
        for month in highlight_months:
            if month in pop_by_month.index:
                ax.scatter(month, pop_by_month[month], color="red", s=100, zorder=3)
        
        st.pyplot(fig3)

        st.write("##### Analyse du graphique")
        st.write("""
        - Janvier : Faible popularit√© (1.5), ce qui pourrait s‚Äôexpliquer par un creux post-f√™tes.
        - F√©vrier - Mars : Augmentation notable, peut-√™tre li√©e aux films sortis autour des Oscars et des vacances d‚Äôhiver.
        - Juin - Ao√ªt : Hausse en √©t√©, ce qui correspond aux blockbusters estivaux.
        - Septembre - Novembre : L√©g√®re baisse, souvent une p√©riode de transition avec moins de grosses sorties.
        - D√©cembre : Pic de popularit√© qui remonte, sans doute gr√¢ce aux sorties de No√´l et aux films familiaux/festifs.
        """)

        st.write("##### Avis 'm√©tier'")
        st.write("Pour maximiser le succ√®s au box-office, il est pr√©f√©rable de programmer la sortie d‚Äôun film durant l‚Äô√©t√© (juin-ao√ªt) ou les f√™tes de fin d‚Äôann√©e (d√©cembre), p√©riodes o√π les films rencontrent le plus de popularit√©.")
        st.write("√Ä l‚Äôinverse, une sortie en janvier ou au d√©but du printemps (mars-avril) pourrait √™tre plus risqu√©e en termes d‚Äôaudience.")

        st.write("##### Conclusion & Exploitation")
        st.write("Si la popularit√© d'un film est fortement influenc√© par son mois de sortie, il pourrait √™tre int√©ressant d'int√©grer cette variable dans notre mod√®le pr√©dictif.")

    with tab3:
        st.title("Popularit√© moyenne par genre")

        # Nettoyage de la variable 'Genres_clean'
        df_filtered = df_until_2023_sorted
        df_filtered['Genres_clean'] = df_filtered['Genres_clean'].fillna('')

        df_filtered['Genres_clean'] = df_filtered['Genres_clean'].apply(lambda x: [genre.strip() for genre in x] if isinstance(x, list) else [genre.strip() for genre in x.split(',') if genre.strip() != ''])

        df_filtered_exploded = df_filtered.explode('Genres_clean')
        df_filtered_exploded = df_filtered_exploded[df_filtered_exploded['Genres_clean'] != '']

        # Calculer la popularit√© moyenne par genre
        genre_popularity_filtered = df_filtered_exploded.groupby('Genres_clean')['popularity'].mean().sort_values(ascending=True)

        fig4, ax = plt.subplots(figsize=(12,8))
        ax.barh(genre_popularity_filtered.index, genre_popularity_filtered.values, color=plt.cm.YlOrRd_r(range(len(genre_popularity_filtered))))
        ax.set_xlabel("Popularit√© moyenne")
        ax.set_ylabel("Genre")
        ax.set_title("Popularit√© moyenne par genre (donn√©es filtr√©es)")
        st.pyplot(fig4)

        st.write("##### Analyse du graphique")
        st.write("Ce graphique met en √©vidence une forte popularit√© des films d'aventure, suivis de pr√®s par l'action et la science-fiction. √Ä l'inverse, les documentaires et les films musicaux enregistrent une popularit√© bien plus faible. L'√©cart entre les films les plus et les moins populaires est significatif, soulignant une nette pr√©f√©rence du public pour les films √† grand spectacle.")

        st.write("##### Avis 'm√©tier'")
        st.write("Pour maximiser la popularit√© d‚Äôun film, il est recommand√© d‚Äôopter pour un genre pl√©biscit√© comme l‚Äôaventure, l‚Äôaction ou la science-fiction. Ces genres attirent un large public gr√¢ce √† leurs effets sp√©ciaux, leurs intrigues dynamiques et leur accessibilit√© internationale.")
        st.write("Cependant, un film appartenant √† un genre moins populaire (romance, documentaire, musique, etc.) peut tout de m√™me rencontrer le succ√®s en misant sur un casting fort et une r√©alisation de qualit√©, qui peuvent compenser un int√©r√™t initial plus faible.")

        st.write("##### Conclusion & Exploitation")
        st.write("Le genre d‚Äôun film a un impact significatif sur sa popularit√© et doit √™tre pris en compte dans la pr√©diction du succ√®s au box-office. Cette variable pourra √™tre int√©gr√©e au mod√®le pr√©dictif pour affiner les estimations en fonction des pr√©f√©rences du public.")
        
    with tab4:
        st.title("Distribution de la popularit√© par cat√©gorie de budget")

        # Distribution de la popularit√© par cat√©gorie de budget
        df_filtered = df_until_2023_sorted.copy()
        df_filtered = df_filtered[df_filtered['popularity'] <= 3000]

        bins = [0, 1e6, 10e6, 100e6, np.inf]
        labels = ["0-1M", "1M-10M", "10M-100M", "100M+"]
        df_filtered["budget_category"] = pd.cut(df_filtered["Budget"], bins=bins, labels=labels)

        fig5, ax = plt.subplots(figsize=(12,8))
        sns.stripplot(x="budget_category", y="popularity", data=df_filtered,
                      jitter=True, size=3, alpha=1, palette="YlOrRd")
        ax.set_xlabel("Cat√©gorie de budget")
        ax.set_ylabel("Popularit√©")
        ax.set_title("Distribution de la popularit√© par cat√©gorie de budget (jusqu'√† 2023) - Strip Plot")
        st.pyplot(fig5)

        st.write("##### Analyse du graphique")
        st.write("Le graphique montre que les films avec un budget inf√©rieur √† 10M ont g√©n√©ralement une popularit√© plus faible. √Ä l‚Äôinverse, les films b√©n√©ficiant d‚Äôun budget sup√©rieur √† 10M pr√©sentent une plus grande dispersion de popularit√©, avec plusieurs d‚Äôentre eux atteignant des niveaux tr√®s √©lev√©s.")

        st.write("##### Avis 'm√©tier'")
        st.write("Le budget d‚Äôun film ne d√©termine pas √† lui seul son succ√®s. On observe que des films tr√®s populaires existent dans toutes les cat√©gories de budget. Cependant, un budget plus √©lev√© semble augmenter les chances qu‚Äôun film atteigne une popularit√© importante, probablement en raison d‚Äôun meilleur marketing, d‚Äôun casting attractif et de meilleures ressources techniques.")

        st.write("##### Conclusion & Exploitation")
        st.write("Bien que le budget ne soit pas le facteur principal de la popularit√© d‚Äôun film, il peut jouer un r√¥le utile dans son succ√®s. Il serait donc pertinent de l‚Äôinclure comme variable dans le mod√®le pr√©dictif, mais en le combinant avec d‚Äôautres facteurs comme le genre, le casting et la date de sortie.")

    with tab5:
        st.title("Distribution des langues originales par popularit√© moyenne")

        # Distribution des langues originales par popularit√© moyenne
        df_filtered = df_until_2023_sorted.copy()
        df_filtered = df_filtered[df_filtered['original_language'].notnull()]
        language_popularity = df_filtered.groupby('original_language')['popularity'].mean().sort_values(ascending=False).head(10)
        lang_mapping = {'en': 'English','fr': 'French','es': 'Spanish','it': 'Italian','de': 'German','ko': 'Korean','ja': 'Japanese','hi': 'Hindi','pt': 'Portuguese','ru': 'Russian','tn': 'Tswana','su': 'Sundanese','no': 'Norwegian','lv': 'Latvian','cn': 'Chinese','te': 'Telugu','dz': 'Dzongkha','yo': 'Yoruba','da': 'Danish'}
        language_popularity.index = language_popularity.index.map(lambda x: lang_mapping.get(x, x))

        # Tracer le graphique
        fig6, ax = plt.subplots(figsize=(12,8))
        ax.barh(y=language_popularity.index, width=language_popularity.values, color=plt.cm.YlOrRd_r(range(len(language_popularity))))
        ax.set_xlabel("Popularit√© moyenne")
        ax.set_ylabel("Langue originale")
        ax.set_title("Top 10 des langues originales par popularit√© moyenne")
        st.pyplot(fig6)

        st.write("##### Analyse du graphique")
        st.write("On observe un pic de populartit√© pour les films en tswana avec une note moyenne de 8.5. Cependant, les autres langues tournent autour de 3 √† 5.5 de moyenne ce qui reste relativement homog√®ne.")

        st.write("##### Avis 'm√©tier'")
        st.write("La langue d‚Äôun film pourrait influencer sa popularit√©, mais en dehors du cas particulier du tswana, aucune tendance marqu√©e ne se d√©gage. Cette anomalie peut √™tre due √† un faible nombre de films dans cette langue, ce qui fausse la moyenne.")

        st.write("##### Conclusion & Exploitation")
        st.write("La langue originale du film pourrait √™tre ajout√©e au mod√®le de pr√©diction, mais son impact semble limit√©. Elle pourrait √™tre utile en compl√©ment d‚Äôautres variables comme le genre ou le pays de distribution.")

    with tab6:
        st.title("Distribution des acteurs par popularit√© et par weighted rating")

        # Nettoyage de la variable "Actors"
        df_actors = df_until_2023_sorted.copy()
        df_actors['Actors'] = df_actors['Actors'].fillna('')
        df_actors['Actors'] = df_actors['Actors'].apply(lambda x: x if isinstance(x, list) else [actor.strip() for actor in x.split(',') if actor.strip() != ''])

        df_actors_exploded = df_actors.explode('Actors')
        df_actors_exploded = df_actors_exploded[df_actors_exploded['Actors'] != "Unknown"]
        
        actor_popularity = df_actors_exploded.groupby('Actors')['popularity'].mean()

        # Calculer la popularit√© moyenne par acteurs
        actor_weighted_rating = df_actors_exploded.groupby('Actors')['weighted_rating'].mean()
        actor_counts = df_actors_exploded['Actors'].value_counts()
        actor_stats = pd.DataFrame({'avg_popularity': actor_popularity,'avg_weighted_rating': actor_weighted_rating,'film_count': actor_counts})

        # Tracer le graphique
        def plot_actors(min_popularity, min_weighted_rating):
        # Filtre les acteurs selon min_popularity et min_weighted_rating, calcule un score combin√© (avg_popularity + avg_weighted_rating), trie et affiche un barplot du top 100."""
            global actor_stats
            actor_stats_filtered = actor_stats[(actor_stats['avg_popularity'] >= min_popularity) & (actor_stats['avg_weighted_rating'] >= min_weighted_rating)].copy()
            actor_stats_filtered['combined_score'] = (actor_stats_filtered['avg_popularity'] + actor_stats_filtered['avg_weighted_rating'])
            actor_stats_sorted = actor_stats_filtered.sort_values(by='combined_score', ascending=False)

            top100_actors = actor_stats_sorted.head(100)

            fig7, ax = plt.subplots(figsize=(12,20))
            ax.barh(y=top100_actors.index, width=top100_actors['combined_score'], color=plt.cm.YlOrRd_r(range(len(top100_actors))))
            ax.set_xlabel("Score combin√© (Popularit√© + Weighted Rating)", fontsize=14)
            ax.set_ylabel("Acteur", fontsize=14)
            ax.set_title(f"Top 100 Acteurs (pop ‚â• {min_popularity}, WR ‚â• {min_weighted_rating})", fontsize=16)
            plt.xticks(fontsize=12)
            plt.yticks(fontsize=12)
            plt.tight_layout()
            st.pyplot(fig7)

        st.write("##### Analyse du graphique")
        st.write("Ce graphique pr√©sente les 100 acteurs ayant une popularit√© ‚â• 1.0 et un Weighted Rating (WR) ‚â• 7.0.")
        st.write("Peter Crombie se d√©marque nettement en t√™te du classement.")
        st.write("Les premiers acteurs affichent une l√©g√®re d√©croissance en popularit√© avant une stabilisation progressive. On observe une r√©partition assez homog√®ne parmi le reste des acteurs, avec une baisse progressive des scores.")

        st.write("##### Avis 'm√©tier'")
        st.write("L‚Äôanalyse de la distribution des acteurs en fonction de leur popularit√© et de leur weighted rating permet d‚Äôidentifier des tendances int√©ressantes.")
        st.write("Certains noms sont peu connus du grand public, ce qui pourrait indiquer un biais li√© aux films r√©cents ou √† des productions sp√©cifiques ayant b√©n√©fici√© d‚Äôun bon accueil critique.")
        st.write("Il est possible que certains acteurs figurent en t√™te du classement en raison de films r√©cents ayant eu une forte exposition m√©diatique.")

        st.write("##### Conclusion & Exploitation")
        st.write("L'int√©gration des acteurs dans le mod√®le de pr√©diction peut √™tre pertinente.")
        st.write("La popularit√© d‚Äôun film peut √™tre fortement influenc√©e par la pr√©sence de certains acteurs en t√™te d'affiche.")
        st.write("Leur score combin√© (Popularit√© + Weighted Rating) pourrait apporter une valeur ajout√©e, notamment pour les films √† fort budget misant sur des t√™tes d‚Äôaffiche.")
        plot_actors(1.0, 7.0)

    with tab7:
        st.title("Distribution des r√©alisateurs par popularit√© et par weighted rating")

        # Nettoyage de la variable "Director"
        df_directors = df_until_2023_sorted.copy()
        df_directors['Director'] = df_directors['Director'].fillna('')
        df_directors['Director'] = df_directors['Director'].apply(lambda x: x if isinstance(x, list) else [dir.strip() for dir in x.split(',') if dir.strip() != ''])

        df_directors_exploded = df_directors.explode('Director')
        df_directors_exploded = df_directors_exploded[df_directors_exploded['Director'] != "Unknown"]
        director_popularity = df_directors_exploded.groupby('Director')['popularity'].mean()

        # Calculer la popularit√© moyenne par directors
        director_weighted_rating = df_directors_exploded.groupby('Director')['weighted_rating'].mean()
        director_counts = df_directors_exploded['Director'].value_counts()
        director_stats = pd.DataFrame({'avg_popularity': director_popularity,'avg_weighted_rating': director_weighted_rating,'film_count': director_counts})

        # Tracer le graphique
        def plot_directors(min_popularity, min_weighted_rating):
        # Filtre les r√©alisateurs selon min_popularity et min_weighted_rating, calcule le combined_score (pop + weighted_rating), trie et affiche un barplot du top 100.
            global director_stats
            director_stats_filtered = director_stats[(director_stats['avg_popularity'] >= min_popularity) & (director_stats['avg_weighted_rating'] >= min_weighted_rating)].copy()
            director_stats_filtered['combined_score'] = (director_stats_filtered['avg_popularity'] + director_stats_filtered['avg_weighted_rating'])

            director_stats_sorted = director_stats_filtered.sort_values(by='combined_score', ascending=False)
            top100_directors = director_stats_sorted.head(100)

            fig8, ax = plt.subplots(figsize=(20,20))
            ax.barh(y=top100_directors.index, width=top100_directors['combined_score'], color=plt.cm.YlOrRd_r(range(len(top100_directors))))
            ax.set_xlabel("Score combin√© (Popularit√© + Weighted Rating)", fontsize=14)
            ax.set_ylabel("R√©alisateur", fontsize=14)
            ax.set_title(f"Top 100 R√©alisateurs (pop ‚â• {min_popularity}, WR ‚â• {min_weighted_rating})", fontsize=16)
            plt.xticks(fontsize=12)
            plt.yticks(fontsize=12)
            plt.tight_layout()
            st.pyplot(fig8)

        st.write("##### Analyse du graphique")
        st.write("Le graphique met en √©vidence les r√©alisateurs les mieux class√©s en fonction d‚Äôun score combin√©, int√©grant popularit√© et note moyenne pond√©r√©e (WR).")
        st.write("Domination des r√©alisateurs d‚Äôanimation : Jared Bush, Rodney Rothman, Bob Persichetti et Josh Cooley arrivent en t√™te. L‚Äôanimation est un genre rentable, souvent associ√© √† des films bien not√©s sur des plateformes comme IMDb.")
        st.write("Absence des grands noms du cin√©ma : Spielberg, Nolan ou Tarantino ne figurent pas dans le classement. Cela sugg√®re que l‚Äôalgorithme favorise les films r√©cents ayant un fort impact imm√©diat plut√¥t que les r√©alisateurs au long palmar√®s.")
        
        st.write("##### Avis 'm√©tier'")
        st.write("Ce classement met en avant une nouvelle g√©n√©ration de r√©alisateurs, particuli√®rement dans l‚Äôanimation. Il souligne aussi le fait que des films bien not√©s mais moins populaires peuvent surpasser ceux de r√©alisateurs embl√©matiques, ce qui sugg√®re que la popularit√© brute ne suffit pas √† garantir une position √©lev√©e.")

        st.write("##### Conclusion & Exploitation")
        st.write("Le succ√®s d‚Äôun film peut √™tre fortement corr√©l√© au r√©alisateur. Certains noms fonctionnent mieux en fonction du genre cin√©matographique et de la popularit√© associ√©e. On peut donc l'int√©grer dans le mod√®le de pr√©diction.")
        plot_directors(1.0, 7.0)

elif page == pages[3]:
    st.write("### Pr√©-processing")
    st.image("DeusExMachina.jpg", width=700)
    st.markdown(
        """
        <style>
        /* Animation pour les boutons sur la page 3 - mise √† jour pour ressembler aux boutons de la page Mod√©lisation / Machine Learning */
        div.stButton > button {
          transition: transform 0.3s ease, background 0.3s ease, box-shadow 0.3s ease;
        }
        div.stButton > button:hover {
          transform: scale(1.05);
          background: linear-gradient(180deg, #dce4eb, #bcc4cd);
          box-shadow: 0 6px 12px rgba(0,0,0,0.2);
          color: #333333;
        }
        </style>
        """,
        unsafe_allow_html=True
    )
    
    if 'df' not in st.session_state:
        st.session_state.df = None

    # √âtape 1 : Chargement des donn√©es
    if st.button("Charger les donn√©es"):
        df = pd.read_csv("df_github.csv")
        st.write(f"‚úÖ Donn√©es charg√©es : {df.shape[0]} lignes, {df.shape[1]} colonnes")
        st.write(df.head())
        st.session_state.df = df

    # √âtape 2 : Conversion en datetime et filtrage par ann√©e
    if st.button("Conversion en datetime et filtrage par ann√©e"):
        df = st.session_state.df if st.session_state.df is not None else pd.read_csv("df_github.csv")
        df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')
        df = df[(df['release_date'].dt.year >= 1995) & (df['release_date'].dt.year <= 2023)]
        st.write("Dimensions apr√®s filtrage :", df.shape)
        st.session_state.df = df

    # √âtape 3 : V√©rification et suppression des valeurs manquantes
    if st.button("V√©rifier et supprimer les NaN"):
        df = st.session_state.df
        # Calcul du taux de NaN pour chaque colonne
        nan_percent = (df.isna().sum() / len(df)) * 100
        st.write("### Taux de NaN (%) par colonne :")
        st.table(nan_percent.reset_index().rename(columns={'index': 'Colonne', 0: 'Pourcentage'}))

        # Option d'afficher un aper√ßu des lignes contenant des NaN
        if st.checkbox("Afficher un aper√ßu des lignes avec des NaN"):
            df_nan = df[df.isna().any(axis=1)]
            st.dataframe(df_nan.head())

        # Suppression des lignes avec 3 NaN ou plus et des lignes sans 'Recettes'
        df_clean = df.loc[(df.isna().sum(axis=1)) < 3].dropna(subset=['Recettes'])
        st.write("Dimensions apr√®s suppression des lignes probl√©matiques :", df_clean.shape)
        st.write("Nombre de lignes supprim√©es :", df.shape[0] - df_clean.shape[0])
        st.session_state.df = df_clean

    # √âtape 4 : Extraction des informations temporelles
    if st.button("Extraction des informations temporelles"):
        df = st.session_state.df
        df['year'] = df['release_date'].dt.year
        df['month'] = df['release_date'].dt.month
        df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)
        df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)
        df.drop(["release_date", "month"], axis=1, inplace=True)
        st.write("Extraction des informations temporelles effectu√©e.")
        st.session_state.df = df

    # √âtape 5 : Traitement des colonnes textuelles
    if st.button("Traitement des colonnes textuelles"):
        df = st.session_state.df
        for col in ['Director', 'Actors', 'Genres_clean']:
            df[col] = df[col].fillna("Unknown")
            df[col] = df[col].apply(lambda x: [s.strip() for s in x.split(',')])
        df['Director'] = df['Director'].apply(lambda x: x[0] if len(x) > 0 else "Unknown")
        df['Actors'] = df['Actors'].apply(lambda x: x[0] if len(x) > 0 else "Unknown")
        df['Genres_clean'] = df['Genres_clean'].apply(lambda x: x[0] if len(x) > 0 else "Unknown")
        st.write("Traitement des colonnes textuelles effectu√©.")
        st.session_state.df = df

    # √âtape 6 : Calcul du logarithme des Recettes
    if st.button("Calcul logarithme des Recettes"):
        df = st.session_state.df
        df['log_Recettes'] = np.log1p(df['Recettes'])
        st.write("Calcul logarithme des Recettes effectu√©.")
        st.session_state.df = df

    # √âtape 7 : Calcul du weighted_rating
    if st.button("Calcul du weighted_rating"):
        df = st.session_state.df
        C = df['vote_average'].mean()
        m_val = df['vote_count'].quantile(0.90)
        def weighted_rating(row):
            v = row['vote_count']
            R = row['vote_average']
            return (v / (v + m_val)) * R + (m_val / (v + m_val)) * C if (v + m_val) != 0 else R
        df['weighted_rating'] = df.apply(weighted_rating, axis=1)
        df.drop(["vote_count", "vote_average"], axis=1, inplace=True)
        st.write("Calcul du weighted_rating effectu√©.")
        st.session_state.df = df

    # √âtape 8 : Calcul des moyennes pond√©r√©es pour Director et Actors
    if st.button("Calcul des moyennes pond√©r√©es pour Director et Actors"):
        df = st.session_state.df
        df['director_weighted_avg'] = df.groupby('Director')['weighted_rating'].transform('mean')
        df['actors_weighted_avg'] = df.groupby('Actors')['weighted_rating'].transform('mean')
        st.write("Calcul des moyennes pond√©r√©es effectu√©.")
        st.session_state.df = df

    # √âtape 9 : Gestion du budget
    if st.button("Gestion du budget"):
        df = st.session_state.df
        df.loc[df['Budget'] == 1.0, 'Budget'] = 0
        df['is_blockbuster'] = (df['Budget'] >= 50000000).astype(int)
        df['actors_budget_interaction'] = df['actors_weighted_avg'] * df['Budget']
        df['log_Budget'] = np.log1p(df['Budget'])
        st.write("Gestion du budget effectu√©e.")
        st.session_state.df = df

    # √âtape 10 : Imputation des valeurs manquantes
    if st.button("Imputation des valeurs manquantes"):
        df = st.session_state.df
        df['Budget'] = df.groupby("Genres_clean")['Budget'].transform(lambda x: x.fillna(x.median()))
        df['Recettes'] = df.groupby("Genres_clean")['Recettes'].transform(lambda x: x.fillna(x.median()))
        df['Budget'] = df.groupby("weighted_rating")['Budget'].transform(lambda x: x.fillna(x.median()))
        df['Recettes'] = df.groupby("weighted_rating")['Recettes'].transform(lambda x: x.fillna(x.median()))
        st.write("Imputation des valeurs manquantes effectu√©e.")
        st.write("NaN Budget :", df['Budget'].isna().sum(), " - NaN Recettes :", df['Recettes'].isna().sum())
        st.session_state.df = df

    # √âtape 11 : Afficher le dataframe final
    if st.button("Afficher le dataframe final"):
        df = st.session_state.df
        st.write("Dimensions finales :", df.shape)
        st.dataframe(df.head())

elif page == pages[4]:
    import pandas as pd
    import numpy as np
    import matplotlib.pyplot as plt
    import seaborn as sns

    from sklearn.model_selection import train_test_split
    from sklearn.impute import SimpleImputer
    from sklearn.preprocessing import LabelEncoder, MinMaxScaler
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.metrics import mean_squared_error, r2_score
    import joblib
    import streamlit as st

    st.title("Mod√©lisation et Machine Learning ‚öôÔ∏è")
    # Afficher la photo Arrival.jpg (assure-toi qu'elle est bien dans le m√™me dossier)
    st.image("Arrival.jpg", width=700)

    st.write("Nous allons relancer toutes les √©tapes du pipeline : chargement, feature engineering, imputation, entra√Ænement du mod√®le...")

    # Bouton pour lancer le pipeline
    if st.button("Relancer le pipeline complet"):
        # -----------------------------
        # 1. Chargement & Nettoyage
        # -----------------------------
        df = pd.read_csv("df_github.csv")
        st.write(f"‚úÖ Donn√©es charg√©es : {df.shape[0]} lignes, {df.shape[1]} colonnes")

        # Filtrage
        df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')
        df = df[(df['release_date'].dt.year >= 1995) & (df['release_date'].dt.year <= 2023)]
        st.write("Dimensions apr√®s filtrage :", df.shape)

        # Suppression des lignes probl√©matiques
        df = df.loc[(df.isna().sum(axis=1)) < 3]
        df = df.dropna(subset=['Recettes'])
        st.write("Dimensions apr√®s suppression des NaN :", df.shape)

        # -----------------------------
        # 2. Feature Engineering
        # -----------------------------
        df['year'] = df['release_date'].dt.year
        df['month'] = df['release_date'].dt.month
        df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)
        df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)
        df.drop(["release_date", "month"], axis=1, inplace=True)

        for col in ['Director', 'Actors', 'Genres_clean']:
            df[col] = df[col].fillna("Unknown")
            df[col] = df[col].apply(lambda x: [s.strip() for s in x.split(',')])
        df['Director'] = df['Director'].apply(lambda x: x[0] if isinstance(x, list) and len(x) > 0 else "Unknown")
        df['Actors'] = df['Actors'].apply(lambda x: x[0] if isinstance(x, list) and len(x) > 0 else "Unknown")
        df['Genres_clean'] = df['Genres_clean'].apply(lambda x: x[0] if isinstance(x, list) and len(x) > 0 else "Unknown")

        # log_Recettes
        df['log_Recettes'] = np.log1p(df['Recettes'])

        # Weighted rating
        C = df['vote_average'].mean()
        m_val = df['vote_count'].quantile(0.90)
        def weighted_rating(row):
            v = row['vote_count']
            R = row['vote_average']
            if (v + m_val) == 0:
                return R
            return (v/(v+m_val))*R + (m_val/(v+m_val))*C
        df['weighted_rating'] = df.apply(weighted_rating, axis=1)
        df.drop(["vote_count", "vote_average"], axis=1, inplace=True)

        director_weighted_avg = df.groupby('Director')['weighted_rating'].mean().to_dict()
        df['director_weighted_avg'] = df['Director'].map(director_weighted_avg)
        actors_weighted_avg = df.groupby('Actors')['weighted_rating'].mean().to_dict()
        df['actors_weighted_avg'] = df['Actors'].map(actors_weighted_avg)
        print("‚úÖ director_weighted_avg keys:", list(director_weighted_avg.keys())[:5])
        print("‚úÖ actors_weighted_avg keys:", list(actors_weighted_avg.keys())[:5])

        df.loc[df['Budget'] == 1.0, 'Budget'] = 0
        df['is_blockbuster'] = (df['Budget'] >= 50000000).astype(int)
        df['actors_budget_interaction'] = df['actors_weighted_avg'] * df['Budget']
        df['log_Budget'] = np.log1p(df['Budget'])

        # -----------------------------
        # 3. Imputation par groupe
        # -----------------------------
        df['Budget'] = df.groupby("Genres_clean")['Budget'].transform(lambda x: x.fillna(x.median()))
        df['Recettes'] = df.groupby("Genres_clean")['Recettes'].transform(lambda x: x.fillna(x.median()))
        df['Budget'] = df.groupby("weighted_rating")['Budget'].transform(lambda x: x.fillna(x.median()))
        df['Recettes'] = df.groupby("weighted_rating")['Recettes'].transform(lambda x: x.fillna(x.median()))

        # -----------------------------
        # 4. Pr√©paration des donn√©es
        # -----------------------------
        X = df.drop(["Recettes", "title", "Budget", "log_Recettes", "weighted_rating"], axis=1)
        y = df['log_Recettes']

        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        # Variables num et cat
        num_train = X_train.select_dtypes(include=["float", "int"])
        cat_train = X_train.select_dtypes(include=["object", "category"])
        num_test = X_test.select_dtypes(include=["float", "int"])
        cat_test = X_test.select_dtypes(include=["object", "category"])

        imputer_num = SimpleImputer(strategy='median')
        num_train_imputed = pd.DataFrame(imputer_num.fit_transform(num_train),
                                        columns=num_train.columns, index=num_train.index)
        num_test_imputed = pd.DataFrame(imputer_num.transform(num_test),
                                        columns=num_test.columns, index=num_test.index)

        imputer_cat = SimpleImputer(strategy='most_frequent')
        cat_train_imputed = pd.DataFrame(imputer_cat.fit_transform(cat_train),
                                        columns=cat_train.columns, index=cat_train.index)
        cat_test_imputed = pd.DataFrame(imputer_cat.transform(cat_test),
                                        columns=cat_test.columns, index=cat_test.index)

        combined_cat = pd.concat([cat_train_imputed, cat_test_imputed])
        le = LabelEncoder()
        for col in cat_train_imputed.columns:
            le.fit(combined_cat[col])
            cat_train_imputed[col] = le.transform(cat_train_imputed[col])
            cat_test_imputed[col] = le.transform(cat_test_imputed[col])

        X_train_final = pd.concat([num_train_imputed, cat_train_imputed], axis=1)
        X_test_final = pd.concat([num_test_imputed, cat_test_imputed], axis=1)

        scaler = MinMaxScaler()
        X_train_scaled = scaler.fit_transform(X_train_final)
        X_test_scaled = scaler.transform(X_test_final)

        # -----------------------------
        # 5. Entra√Ænement du mod√®le
        # -----------------------------
        rf_model = RandomForestRegressor(
            n_estimators=300,
            min_samples_split=5,
            min_samples_leaf=1,
            max_features='sqrt',
            max_depth=20,
            random_state=42,
            bootstrap=False
        )
        rf_model.fit(X_train_scaled, y_train)
        y_pred = rf_model.predict(X_test_scaled)

        mse = mean_squared_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)

        st.write("üîπ Score sur Train :", rf_model.score(X_train_scaled, y_train))
        st.write("üîπ Score sur Test :", rf_model.score(X_test_scaled, y_test))
        st.write("üîπ MSE :", mse)
        st.write("üîπ R¬≤ :", r2)

        # -----------------------------
        # 6. Sauvegarde du pipeline
        # -----------------------------
        pipeline = {
            "model": rf_model,
            "scaler": scaler,
            "label_encoder": le,
            "director_mapping": director_weighted_avg,
            "actor_mapping": actors_weighted_avg,
            "expected_features": X_train_final.columns.tolist()
        }
        print("üîç Cl√©s du pipeline avant sauvegarde:", pipeline.keys())
        joblib.dump(pipeline, "pipeline.joblib")
        st.success("Pipeline complet relanc√© et sauvegard√© !")

elif page == pages[5]:
    import pandas as pd
    import numpy as np
    import joblib
    from sklearn.preprocessing import LabelEncoder, MinMaxScaler
    import streamlit as st
 
    st.title("üé• Application")
    st.image("StarWars.jpg", width=700)
    st.write("Ici, vous pouvez renseigner les informations d‚Äôun film pour obtenir la pr√©diction de ses recettes.")
 
    ##################################
    # FONCTION SAFE POUR L'ENCODAGE
    ##################################
    def safe_label_transform(value, le):
        if value in le.classes_:
            return le.transform([value])[0]
        else:
            if "Unknown" in le.classes_:
                return le.transform(["Unknown"])[0]
            else:
                return -1
 
    ##################################
    # FONCTION DE TRANSFORMATION POUR INF√âRENCE
    ##################################
    def transform_new_data_inference(df_new, scaler, le, director_map, actor_map, expected_features):
        df_trans = df_new.copy()
 
        # Comme la cible Recettes et les votes ne sont pas disponibles √† l'inf√©rence,
        # on cr√©e des colonnes dummy (elles seront supprim√©es apr√®s transformation)
        df_trans["Recettes"] = 0
        df_trans["vote_count"] = 0
        df_trans["vote_average"] = 0.0
 
        # Transformation de la date
        df_trans['release_date'] = pd.to_datetime(df_trans['release_date'], errors='coerce')
        df_trans['year'] = df_trans['release_date'].dt.year
        df_trans['month'] = df_trans['release_date'].dt.month
        df_trans['month_sin'] = np.sin(2 * np.pi * df_trans['month'] / 12)
        df_trans['month_cos'] = np.cos(2 * np.pi * df_trans['month'] / 12)
        df_trans.drop(["release_date", "month"], axis=1, inplace=True)
 
        # Traitement des colonnes textuelles
        for col in ['Director', 'Actors', 'Genres_clean']:
            df_trans[col] = df_trans[col].fillna("Unknown")
            df_trans[col] = df_trans[col].apply(lambda x: [s.strip() for s in x.split(',')])
        df_trans['Director'] = df_trans['Director'].apply(lambda x: x[0] if isinstance(x, list) and len(x) > 0 else "Unknown")
        df_trans['Actors'] = df_trans['Actors'].apply(lambda x: x[0] if isinstance(x, list) and len(x) > 0 else "Unknown")
        df_trans['Genres_clean'] = df_trans['Genres_clean'].apply(lambda x: x[0] if isinstance(x, list) and len(x) > 0 else "Unknown")
 
        # Comme nous n'avons pas de v√©ritables Recettes ni votes, on d√©finit ces colonnes sur 0
        df_trans['log_Recettes'] = 0
        df_trans['weighted_rating'] = 0
 
        # Gestion du budget et cr√©ation d'interactions
        df_trans.loc[df_trans['Budget'] == 1.0, 'Budget'] = 0
        df_trans['is_blockbuster'] = (df_trans['Budget'] >= 50000000).astype(int)
        df_trans['actors_weighted_avg'] = df_trans['Actors'].apply(lambda x: actor_map.get(x, 0))
        df_trans['actors_budget_interaction'] = df_trans['actors_weighted_avg'] * df_trans['Budget']
        df_trans['log_Budget'] = np.log1p(df_trans['Budget'])
 
        # Ajout du mapping pour le r√©alisateur
        # on prend la moyenne si le r√©alisateur n'est pas connu
        df_trans["director_weighted_avg"] = df_trans["Director"].apply(lambda x: director_map.get(x, np.mean(list(director_map.values()))))
 
        # On int√®gre la note de popularit√© saisie et on cr√©e la colonne release_year
        df_trans["release_year"] = df_trans["year"]
 
        # Pr√©paration finale : suppression des colonnes non utilis√©es √† l'inf√©rence
        X_new = df_trans.drop(["Recettes", "title", "Budget", "log_Recettes", "weighted_rating"], axis=1)
 
        # S√©paration en variables num√©riques et cat√©gorielles
        X_num = X_new.select_dtypes(include=["float", "int"])
        X_cat = X_new.select_dtypes(include=["object", "category"])
 
        # Encodage safe des variables cat√©gorielles
        for col in X_cat.columns:
            X_cat[col] = X_cat[col].apply(lambda x: safe_label_transform(x, le))
 
        X_new_final = pd.concat([X_num, X_cat], axis=1)
        # R√©indexer pour que l'ordre des colonnes corresponde aux features utilis√©es lors de l'entra√Ænement
        X_new_final = X_new_final.reindex(columns=expected_features)
 
        # Optionnel : affichage interm√©diaire pour v√©rification
        st.write("**Aper√ßu avant scaling**", X_new_final.head())
 
        X_new_scaled = scaler.transform(X_new_final)
        return X_new_scaled
 
    # Chargement du pipeline sauvegard√©
    joblib_url = "https://github.com/MovieForecasting/DA_Project_Movieforecasting/releases/download/JR/pipeline.joblib"
    response = requests.get(joblib_url)
    pipeline = joblib.load(io.BytesIO(response.content))
    print("üîç Cl√©s du pipeline charg√©:", pipeline.keys())
 
    st.write("#### Veuillez saisir les informations du film :")
 
    with st.form("my_form"):
        import datetime
        release_date = st.date_input("Date de sortie :", value=datetime.date(2017, 12, 15))
        Budget = st.number_input("Budget (en dollars):", min_value=0, value=317000000)
        Director = st.text_input("Nom du r√©alisateur:", value="Rian Johnson")
        Actors = st.text_input("Liste des acteurs (s√©par√©s par une virgule):", value="Daisy Ridley, John Boyega, Adam Driver")
        genres = ["Action", "Aventure", "Com√©die", "Drame", "Science Fiction", "Horreur", "Romance", "Thriller", "Animation", "Documentaire"]
        Genres_clean = st.selectbox("Genre principal:", options=genres, index=genres.index("Science Fiction"))
        popularity_options = [
            "0-100 (Pas populaire)",
            "100-500 (Ind√©pendant)",
            "500-1000 (Plut√¥t populaire)",
            "1000-5000 (Populaire)",
            "5000+ (Tr√®s populaire)"
        ]
        
        # Selectbox for choosing the popularity range
        popularity_range = st.selectbox("S√©lectionnez le niveau de popularit√© :", options=popularity_options, index=popularity_options.index("5000+ (Tr√®s populaire)"))
        
        # Mapping from the selected range to a representative numeric value
        popularity_mapping = {
            "0-100 (Pas populaire)": 50,
            "100-500 (Ind√©pendant)": 300,
            "500-1000 (Plut√¥t populaire)": 750,
            "1000-5000 (Populaire)": 3000,
            "5000+ (Tr√®s populaire)": 8000
        }
        
        popularity = popularity_mapping[popularity_range]
 
        submitted = st.form_submit_button("Pr√©dire les recettes")
        if submitted:
            data_future = {
                "title": ["Rentrer le titre du film"],
                "release_date": [release_date],
                "Budget": [Budget],
                "Director": [Director],
                "Actors": [Actors],
                "Genres_clean": [Genres_clean],
                "popularity": [popularity]  # On inclut la popularit√© ici
            }
            df_future = pd.DataFrame(data_future)
            
            # V√©rification de l'existence du r√©alisateur
            director_input = Director.strip()
            if director_input in pipeline["director_mapping"]:
                st.info(f"Le r√©alisateur '{director_input}' est reconnu dans notre dataset.")
            else:
                st.warning(f"Le r√©alisateur '{director_input}' n'est pas reconnu dans notre dataset.")
 
            # V√©rification de l'existence des acteurs
            actor_inputs = [actor.strip() for actor in Actors.split(",")]
            recognized_actors = [actor for actor in actor_inputs if actor in pipeline["actor_mapping"]]
            unrecognized_actors = [actor for actor in actor_inputs if actor not in pipeline["actor_mapping"]]
 
            if recognized_actors:
                st.info(f"Acteurs reconnus: {', '.join(recognized_actors)}")
            if unrecognized_actors:
                st.warning(f"Acteurs non reconnus: {', '.join(unrecognized_actors)}")
 
            # Transformation des donn√©es
            X_future = transform_new_data_inference(df_future,
                                                    pipeline["scaler"],
                                                    pipeline["label_encoder"],
                                                    pipeline["director_mapping"],
                                                    pipeline["actor_mapping"],
                                                    pipeline["expected_features"])
 
            prediction = pipeline["model"].predict(X_future)
            st.write("**Pr√©diction (log_Recettes)**:", prediction[0])
            recettes_pred = np.expm1(prediction)
            st.write("**Pr√©diction (Recettes)**:", recettes_pred[0])
 
            # Affichage en millions
            recettes_millions = recettes_pred[0] / 1e6
            st.success(f"Pr√©diction (Recettes) : {recettes_millions:.2f} millions de dollars")
elif page == pages[6]:
    st.image("Matrix.jpg", width=700)
    st.write("### Conclusion")
    st.write("""
    La d√©marche adopt√©e nous a permis de d√©velopper un mod√®le robuste et fiable pour pr√©dire la performance financi√®re des films. En combinant un traitement rigoureux des donn√©es (gestion des valeurs manquantes, extraction de nouvelles variables pertinentes telles que ‚Äúis_blockbuster‚Äù, l‚Äôinteraction ‚Äúactors_budget_interaction‚Äù et l‚Äôint√©gration de la saisonnalit√©) avec une optimisation pr√©cise des hyper param√®tres du mod√®le Random Forest Regressor via GridSearchCV, nous avons significativement am√©lior√© la performance pr√©dictive.
    
    L‚Äôoptimisation fine des hyper param√®tres a permis une r√©duction notable de l‚Äôoverfitting, avec un score sur le jeu d'entra√Ænement passant de 0.9489 √† 0.9239 et une am√©lioration du score sur le jeu de donn√©es de test de 0.6179 √† 0.6920. Cette progression d√©montre l‚Äôimportance d‚Äôune s√©lection pertinente des variables, notamment l‚Äôinclusion d‚Äôinteractions (comme ‚Äúactors_budget_interaction‚Äù) et des variables temporelles telles que la saisonnalit√©.
    
    En conclusion, ce projet met en √©vidence que notre approche permet de fournir des pr√©dictions fiables et pr√©cises des recettes futures, ouvrant ainsi des perspectives prometteuses pour une exploitation concr√®te dans l‚Äôindustrie du cin√©ma, notamment pour la prise de d√©cisions strat√©giques et financi√®res.
    
    En outre, la r√©solution de l‚Äôoverfitting est un d√©fi fr√©quent en data science. Pour y faire face, des techniques comme la validation crois√©e K-Fold, qui n‚Äôont pas √©t√© abord√©es dans notre formation, pourraient √™tre envisag√©es pour am√©liorer encore la robustesse du mod√®le.
    """)
