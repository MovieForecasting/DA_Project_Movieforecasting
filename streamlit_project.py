import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
from io import StringIO
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
import joblib
from sklearn.metrics import r2_score

st.set_page_config(page_title="Pr√©vision du succ√®s d'un film", page_icon="üé•")

df_exploration = pd.read_csv("df_github.csv")

buffer = StringIO()
df_exploration.info(buf=buffer)
s = buffer.getvalue()

# Transformation du dataframe pour Exploration du Dataset
df_exploration['release_date'] = pd.to_datetime(df_exploration['release_date'], errors='coerce')
df_until_2023 = df_exploration[df_exploration['release_date'].dt.year <= 2023].copy()
df_until_2023_sorted = df_until_2023.sort_values(by='popularity', ascending=False)

st.title("Pr√©vision du succ√®s d'un film")

image_path = "logo_datascientest.png"
st.sidebar.image(image_path, width=180)

st.sidebar.title("Sommaire")

pages=["Pr√©sentation du projet üöÄ", "Exploration du Dataset üßê", "DataViz' üìä", "Pr√©-processing üë®‚Äçüíª", "Mod√©lisation / Machine Learning ‚öôÔ∏è", "Application üé•", "Conclusion üé¨"]

page=st.sidebar.radio("Aller vers", pages)

st.sidebar.write("__Auteurs__")

st.sidebar.write("[Camille Laluque](https://www.linkedin.com/in/camille-cadet-51629b140/)")
st.sidebar.markdown("[Samy Cao](https://www.linkedin.com/in/samy-cao)")
st.sidebar.write("[Jean-No√´l Duchevet](https://www.linkedin.com/in/jean-noel-duchevet/)")
st.sidebar.write("[Tristan Tansu](https://www.linkedin.com/in/tristan-tansu-42009365/)")

st.sidebar.write("Promotion Data Analyst : Janvier 2025")

if page == pages[0]:
    image_path = "image_sommaire.png"
    st.image(image_path, width=700)
    st.write("### Pr√©sentation du projet")
    st.write("Ce projet a √©t√© r√©alis√© dans le cadre de notre formation en Data Analyse via l'organisme Data Scientest.")
    st.write("L'objectif de ce projet est de pr√©dire le succ√®s d'un film au box-office en utilisant le jeu de donn√©e issu de TMDB : 'The Movie DataBase' o√π nous pouvons obtenir des informations comme le budget, les recettes, le genre, les acteurs et les r√©alisateurs.")
    st.write("Gr√¢ce √† l‚Äôanalyse de ces donn√©es, nous pouvons mieux comprendre lesquelles ont une influence dans le succ√®s d'un film.")
  
    st.write("### Probl√©matique")
  
    st.write("Quels sont les √©l√©ments cl√©s qui influencent le succ√®s d‚Äôun film ? Peut-on pr√©dire ce succ√®s √† partir des donn√©es disponibles ?")

elif page == pages[1]:
    
    st.write("### Exploration du Dataset")
    image_path = "image_exploration.png"
    st.image(image_path, width=700)

    st.write("Ci-dessous un aper√ßu du dataset :")
    st.dataframe(df_exploration.head())
    
    st.write("Dimensions du dataframe :")
    
    st.write(df_exploration.shape)

    st.write("Autres informations sur le dataframe :")

    with st.expander("Informations sur le dataset"):
        st.text(s)

    if st.checkbox("Montrer les valeurs manquantes"): 
        st.dataframe(df_exploration.isna().sum())
    
    if st.checkbox("Montrer les doublons") : 
        st.write(df_exploration.duplicated().sum())

elif page == pages[2]:

    st.write("Nous allons ensuite pr√©senter divers graphiques exploitant nos jeux de donn√©es.")

    st.write("### M√©thodologie")

    st.write("#### Variable 'Popularity'")

    st.write("Nous nous int√©ressons √† l'indicateur 'popularity' de TMDB (The Movie Database) qui sera la variable d'analyse exploratoire car il refl√®te la popularit√© d'un film ou d'une s√©rie selon plusieurs crit√®res. L'algorithme de calcul de cet indicateur n'est pas public mais nous savons qu'il est bas√© sur plusieurs facteurs :")
    st.write("""
    - Les vues des pages
    - Les votes des utilisateurs
    - Le nombre d'ajout en 'favoris' et/ou en 'watchlist'
    - Le nombre de recherches sur la plateforme
    - Les mentions sur les r√©seaux
    - Les ann√©es de lancement
    - Le 'popularity score' du jour pr√©c√©dent
             """)
    st.write("L'indicateur de popularit√© refl√®te un caract√®re dynamique. Il peut fluctuer en fonction des tendances actuelles, des sorties r√©centes, ou de l'impact viral sur les plateformes sociales gr√¢ce √† l'interactions des utilisateurs. Plus un film ou une s√©rie est mentionn√© et/ou recherch√©, plus sa popularit√© sera √©lev√©e sur TMDB.")

    st.markdown("[Source TMDB](https://developer.themoviedb.org/docs/popularity-and-trending)")
    st.write("Notre premi√®re approche sur cet indicateur a √©t√© de montrer son √©volution moyenne au fil des ann√©es c'est √† dire de 1980 √† 2025 soit sur l'ensemble des donn√©es de notre dataset.")

    st.write("Rapidement nous nous sommes rendu compte que l'ann√©e 2024 pr√©sente des valeurs extr√™mes de popularit√©. En effet, comme expliqu√© pr√©c√©dement cet indicateur pr√©sente un caract√®re dynamique du fait qu'il est mis √† jour r√©guli√®rement en fonction des param√®tres qui le composent.")

    st.write("##### Avis 'm√©tier'")

    st.write("A titre d'exemple, nous pouvons penser que les films sorti en 2024 dans notre dataset dont certains qui l'ont √©t√© r√©cemment notamment sur le mois de d√©cembre, ont un score √©lev√© de popularit√© car ils suscitent beaucoup d'int√©r√™t et de curiostit√© de la part des utilisateurs. Cela rev√™t donc une importance dans l'analyse de donn√©es temporelles.")
    st.write("Afin de limiter l'impact de ces valeurs sur nos analyses, nous d√©cidons d'exclure les donn√©es relatives √† 2024.")

    st.write("##### Conclusion & Exploitation")

    st.write("Ce travail d'exploration va s'articuler autour de la variable 'popularity' notamment sa saisonalit√© et son interaction avec diff√©rentes variables telles que le genre, le budget, les r√©alisateurs et les acteurs.")
    
    image_path = "boxplot_popularity2024.png"
    st.image(image_path, width=600)

    # Ajout d'onglets
    tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs(["DataViz' 1", "DataViz' 2", "DataViz' 3","DataViz' 4","DataViz' 5","DataViz' 6","DataViz' 7"])

    # Ajouter du contenu dans chaque onglet
    with tab1:
        st.title("Evolution de la popularit√© des films au fil des ann√©es")

        avg_popularity = df_until_2023_sorted.groupby('release_year')['popularity'].mean()
        fig2, ax = plt.subplots(figsize=(10, 6))
        ax.plot(avg_popularity.index, avg_popularity.values)
        ax.set_title("Evolution de la popularit√© moyenne des films au fil des ann√©es");
        ax.set_xlabel("Ann√©e")
        ax.set_ylabel("Popularit√©")
        st.pyplot(fig2)
        
        st.write("##### Analyse du graphique")
        st.write("""
        Le graphique montre l‚Äô√©volution de la popularit√© moyenne des films en fonction de leur ann√©e de sortie. Plusieurs tendances √©mergent :
        - **Tendance g√©n√©rale √† la hausse :** On observe une augmentation progressive de la popularit√© des films au fil des d√©cennies. Cette tendance peut √™tre li√©e √† une am√©lioration des techniques de production, √† une meilleure accessibilit√© aux films et √† une augmentation du nombre de spectateurs.
        - **Pics et baisses de popularit√© :** Certaines ann√©es affichent des pics, ce qui pourrait √™tre d√ª √† la sortie de films marquants qui ont domin√© le box-office et influenc√© la tendance g√©n√©rale. La baisse notable en 2020 co√Øncide avec la crise sanitaire mondiale, qui a entra√Æn√© une diminution du nombre de films en salle et une r√©duction du nombre de spectateurs.
        """)

        st.write("##### Avis 'm√©tier'")
        st.write("Cette analyse est pertinente pour comprendre l‚Äô√©volution des attentes du public et l‚Äôimpact des grandes tendances cin√©matographiques.")
        st.write("L'augmentation g√©n√©rale de la popularit√© peut √™tre attribu√©e √† l'√©volution du marketing des films, √† l'essor des grandes franchises, ainsi qu'√† une meilleure structuration des sorties en salle.")
        st.write("Les baisses de certaines p√©riodes peuvent √™tre li√©es √† des crises √©conomiques, √† des changements dans l‚Äôindustrie cin√©matographique ou √† une concurrence accrue entre les films.")
        st.write("L‚Äô√©tude de ces variations permet aux producteurs et distributeurs de mieux anticiper le march√© et d‚Äôadapter leurs strat√©gies de sortie.")

        st.write("##### Conclusion & Exploitation")
        st.write("Si l‚Äôann√©e de sortie influence la popularit√©, elle pourrait √™tre int√©gr√©e comme une variable cl√© dans notre mod√®le de pr√©diction du succ√®s au box-office.. Apr√®s lecture du graphique, on remarque une stabilisation √† partir de 1995, il nous semble utile de r√©duite notre jeu de donn√©es de films √† partir cette ann√©e.")

    with tab2:
        st.title("Popularit√© moyenne des films en fonction du mois de sortie")

        if 'release_month' not in df_until_2023_sorted.columns:
            df_until_2023_sorted['release_month'] = df_until_2023_sorted['release_date'].dt.month
        
        pop_by_month = df_until_2023_sorted.groupby('release_month')['popularity'].mean()

        fig3, ax = plt.subplots(figsize=(10,6))
        ax.plot(pop_by_month.index, pop_by_month.values, marker='o', linestyle='-', color='orange')
        ax.set_title("Popularit√© moyenne des films par mois de sortie");
        ax.set_xlabel("Mois")
        ax.set_ylabel("Popularit√© moyenne")

        # Mettre en avant les mois cl√©s
        highlight_months = [7, 12]
        for month in highlight_months:
            if month in pop_by_month.index:
                ax.scatter(month, pop_by_month[month], color="red", s=100, zorder=3)
        
        st.pyplot(fig3)

        st.write("##### Analyse du graphique")
        st.write("""
        - Janvier : Faible popularit√© (1.5), ce qui pourrait s‚Äôexpliquer par un creux post-f√™tes.
        - F√©vrier - Mars : Augmentation notable, peut-√™tre li√©e aux films sortis autour des Oscars et des vacances d‚Äôhiver.
        - Juin - Ao√ªt : Hausse en √©t√©, ce qui correspond aux blockbusters estivaux.
        - Septembre - Novembre : L√©g√®re baisse, souvent une p√©riode de transition avec moins de grosses sorties.
        - D√©cembre : Pic de popularit√© qui remonte, sans doute gr√¢ce aux sorties de No√´l et aux films familiaux/festifs.
        """)

        st.write("##### Avis 'm√©tier'")
        st.write("Pour maximiser le succ√®s au box-office, il est pr√©f√©rable de programmer la sortie d‚Äôun film durant l‚Äô√©t√© (juin-ao√ªt) ou les f√™tes de fin d‚Äôann√©e (d√©cembre), p√©riodes o√π les films rencontrent le plus de popularit√©.")
        st.write("√Ä l‚Äôinverse, une sortie en janvier ou au d√©but du printemps (mars-avril) pourrait √™tre plus risqu√©e en termes d‚Äôaudience.")

        st.write("##### Conclusion & Exploitation")
        st.write("Si la popularit√© d'un film est fortement influenc√© par son mois de sortie, il pourrait √™tre int√©ressant d'int√©grer cette variable dans notre mod√®le pr√©dictif.")

    with tab3:
        st.title("Popularit√© moyenne par genre")

        st.write("##### Analyse du graphique")

        st.write("##### Avis 'm√©tier'")

        st.write("##### Conclusion & Exploitation")
        
    with tab4:
        st.title("Distribution de la popularit√© par cat√©gorie de budget")

        st.write("##### Analyse du graphique")

        st.write("##### Avis 'm√©tier'")

        st.write("##### Conclusion & Exploitation")

    with tab5:
        st.title("Distribution des langues originales par popularit√© moyenne")

        st.write("##### Analyse du graphique")

        st.write("##### Avis 'm√©tier'")

        st.write("##### Conclusion & Exploitation")

    with tab6:
        st.title("Distribution des acteurs par popularit√© et par weighted rating")

        st.write("##### Analyse du graphique")

        st.write("##### Avis 'm√©tier'")

        st.write("##### Conclusion & Exploitation")

    with tab7:
        st.title("Distribution des r√©alisateurs par popularit√© et par weighted rating")

        st.write("##### Analyse du graphique")

        st.write("##### Avis 'm√©tier'")

        st.write("##### Conclusion & Exploitation")

elif page == pages[3]:
    st.write("### Pr√©-processing")

elif page == pages[4]:
    import pandas as pd
    import numpy as np
    import matplotlib.pyplot as plt
    import seaborn as sns

    from sklearn.model_selection import train_test_split
    from sklearn.impute import SimpleImputer
    from sklearn.preprocessing import LabelEncoder, MinMaxScaler
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.metrics import mean_squared_error, r2_score
    import joblib
    import streamlit as st

    st.title("üé¨ Mod√©lisation et Machine Learning - Page Ind√©pendante")
    # Afficher la photo Arrival.jpg (assure-toi qu'elle est bien dans le m√™me dossier)
    st.image("Arrival.jpg", width=700)

    st.write("Nous allons relancer toutes les √©tapes du pipeline : chargement, feature engineering, imputation, entra√Ænement du mod√®le...")

    # Bouton pour lancer le pipeline
    if st.button("Relancer le pipeline complet"):
        # -----------------------------
        # 1. Chargement & Nettoyage
        # -----------------------------
        df = pd.read_csv("df_github.csv")
        st.write(f"‚úÖ Donn√©es charg√©es : {df.shape[0]} lignes, {df.shape[1]} colonnes")

        # Filtrage
        df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')
        df = df[(df['release_date'].dt.year >= 1995) & (df['release_date'].dt.year <= 2023)]
        st.write("Dimensions apr√®s filtrage :", df.shape)

        # Suppression des lignes probl√©matiques
        df = df.loc[(df.isna().sum(axis=1)) < 3]
        df = df.dropna(subset=['Recettes'])
        st.write("Dimensions apr√®s suppression des NaN :", df.shape)

        # -----------------------------
        # 2. Feature Engineering
        # -----------------------------
        df['year'] = df['release_date'].dt.year
        df['month'] = df['release_date'].dt.month
        df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)
        df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)
        df.drop(["release_date", "month"], axis=1, inplace=True)

        for col in ['Director', 'Actors', 'Genres_clean']:
            df[col] = df[col].fillna("Unknown")
            df[col] = df[col].apply(lambda x: [s.strip() for s in x.split(',')])
        df['Director'] = df['Director'].apply(lambda x: x[0] if isinstance(x, list) and len(x) > 0 else "Unknown")
        df['Actors'] = df['Actors'].apply(lambda x: x[0] if isinstance(x, list) and len(x) > 0 else "Unknown")
        df['Genres_clean'] = df['Genres_clean'].apply(lambda x: x[0] if isinstance(x, list) and len(x) > 0 else "Unknown")

        # log_Recettes
        df['log_Recettes'] = np.log1p(df['Recettes'])

        # Weighted rating
        C = df['vote_average'].mean()
        m_val = df['vote_count'].quantile(0.90)
        def weighted_rating(row):
            v = row['vote_count']
            R = row['vote_average']
            if (v + m_val) == 0:
                return R
            return (v/(v+m_val))*R + (m_val/(v+m_val))*C
        df['weighted_rating'] = df.apply(weighted_rating, axis=1)
        df.drop(["vote_count", "vote_average"], axis=1, inplace=True)

        director_weighted_avg = df.groupby('Director')['weighted_rating'].mean().to_dict()
        df['director_weighted_avg'] = df['Director'].map(director_weighted_avg)
        actors_weighted_avg = df.groupby('Actors')['weighted_rating'].mean().to_dict()
        df['actors_weighted_avg'] = df['Actors'].map(actors_weighted_avg)
        print("‚úÖ director_weighted_avg keys:", list(director_weighted_avg.keys())[:5])
        print("‚úÖ actors_weighted_avg keys:", list(actors_weighted_avg.keys())[:5])

        df.loc[df['Budget'] == 1.0, 'Budget'] = 0
        df['is_blockbuster'] = (df['Budget'] >= 50000000).astype(int)
        df['actors_budget_interaction'] = df['actors_weighted_avg'] * df['Budget']
        df['log_Budget'] = np.log1p(df['Budget'])

        # -----------------------------
        # 3. Imputation par groupe
        # -----------------------------
        df['Budget'] = df.groupby("Genres_clean")['Budget'].transform(lambda x: x.fillna(x.median()))
        df['Recettes'] = df.groupby("Genres_clean")['Recettes'].transform(lambda x: x.fillna(x.median()))
        df['Budget'] = df.groupby("weighted_rating")['Budget'].transform(lambda x: x.fillna(x.median()))
        df['Recettes'] = df.groupby("weighted_rating")['Recettes'].transform(lambda x: x.fillna(x.median()))

        # -----------------------------
        # 4. Pr√©paration des donn√©es
        # -----------------------------
        X = df.drop(["Recettes", "title", "Budget", "log_Recettes", "weighted_rating"], axis=1)
        y = df['log_Recettes']

        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        # Variables num et cat
        num_train = X_train.select_dtypes(include=["float", "int"])
        cat_train = X_train.select_dtypes(include=["object", "category"])
        num_test = X_test.select_dtypes(include=["float", "int"])
        cat_test = X_test.select_dtypes(include=["object", "category"])

        imputer_num = SimpleImputer(strategy='median')
        num_train_imputed = pd.DataFrame(imputer_num.fit_transform(num_train),
                                        columns=num_train.columns, index=num_train.index)
        num_test_imputed = pd.DataFrame(imputer_num.transform(num_test),
                                        columns=num_test.columns, index=num_test.index)

        imputer_cat = SimpleImputer(strategy='most_frequent')
        cat_train_imputed = pd.DataFrame(imputer_cat.fit_transform(cat_train),
                                        columns=cat_train.columns, index=cat_train.index)
        cat_test_imputed = pd.DataFrame(imputer_cat.transform(cat_test),
                                        columns=cat_test.columns, index=cat_test.index)

        combined_cat = pd.concat([cat_train_imputed, cat_test_imputed])
        le = LabelEncoder()
        for col in cat_train_imputed.columns:
            le.fit(combined_cat[col])
            cat_train_imputed[col] = le.transform(cat_train_imputed[col])
            cat_test_imputed[col] = le.transform(cat_test_imputed[col])

        X_train_final = pd.concat([num_train_imputed, cat_train_imputed], axis=1)
        X_test_final = pd.concat([num_test_imputed, cat_test_imputed], axis=1)

        scaler = MinMaxScaler()
        X_train_scaled = scaler.fit_transform(X_train_final)
        X_test_scaled = scaler.transform(X_test_final)

        # -----------------------------
        # 5. Entra√Ænement du mod√®le
        # -----------------------------
        rf_model = RandomForestRegressor(
            n_estimators=300,
            min_samples_split=5,
            min_samples_leaf=1,
            max_features='sqrt',
            max_depth=20,
            random_state=42,
            bootstrap=False
        )
        rf_model.fit(X_train_scaled, y_train)
        y_pred = rf_model.predict(X_test_scaled)

        mse = mean_squared_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)

        st.write("üîπ Score sur Train :", rf_model.score(X_train_scaled, y_train))
        st.write("üîπ Score sur Test :", rf_model.score(X_test_scaled, y_test))
        st.write("üîπ MSE :", mse)
        st.write("üîπ R¬≤ :", r2)

        # -----------------------------
        # 6. Sauvegarde du pipeline
        # -----------------------------
        pipeline = {
            "model": rf_model,
            "scaler": scaler,
            "label_encoder": le,
            "director_mapping": director_weighted_avg,
            "actor_mapping": actors_weighted_avg,
            "expected_features": X_train_final.columns.tolist()
        }
        print("üîç Cl√©s du pipeline avant sauvegarde:", pipeline.keys())
        joblib.dump(pipeline, "pipeline.joblib")
        st.success("Pipeline complet relanc√© et sauvegard√© !")

elif page == pages[5]:
    import pandas as pd
    import numpy as np
    import joblib
    from sklearn.preprocessing import LabelEncoder, MinMaxScaler
    import streamlit as st
 
    st.title("üé• Application ‚Äì Inf√©rence")
    st.write("Ici, vous pouvez renseigner les informations d‚Äôun film pour obtenir la pr√©diction de ses recettes.")
 
    ##################################
    # FONCTION SAFE POUR L'ENCODAGE
    ##################################
    def safe_label_transform(value, le):
        if value in le.classes_:
            return le.transform([value])[0]
        else:
            if "Unknown" in le.classes_:
                return le.transform(["Unknown"])[0]
            else:
                return -1
 
    ##################################
    # FONCTION DE TRANSFORMATION POUR INF√âRENCE
    ##################################
    def transform_new_data_inference(df_new, scaler, le, director_map, actor_map, expected_features):
        df_trans = df_new.copy()
 
        # Comme la cible Recettes et les votes ne sont pas disponibles √† l'inf√©rence,
        # on cr√©e des colonnes dummy (elles seront supprim√©es apr√®s transformation)
        df_trans["Recettes"] = 0
        df_trans["vote_count"] = 0
        df_trans["vote_average"] = 0.0
 
        # Transformation de la date
        df_trans['release_date'] = pd.to_datetime(df_trans['release_date'], errors='coerce')
        df_trans['year'] = df_trans['release_date'].dt.year
        df_trans['month'] = df_trans['release_date'].dt.month
        df_trans['month_sin'] = np.sin(2 * np.pi * df_trans['month'] / 12)
        df_trans['month_cos'] = np.cos(2 * np.pi * df_trans['month'] / 12)
        df_trans.drop(["release_date", "month"], axis=1, inplace=True)
 
        # Traitement des colonnes textuelles
        for col in ['Director', 'Actors', 'Genres_clean']:
            df_trans[col] = df_trans[col].fillna("Unknown")
            df_trans[col] = df_trans[col].apply(lambda x: [s.strip() for s in x.split(',')])
        df_trans['Director'] = df_trans['Director'].apply(lambda x: x[0] if isinstance(x, list) and len(x) > 0 else "Unknown")
        df_trans['Actors'] = df_trans['Actors'].apply(lambda x: x[0] if isinstance(x, list) and len(x) > 0 else "Unknown")
        df_trans['Genres_clean'] = df_trans['Genres_clean'].apply(lambda x: x[0] if isinstance(x, list) and len(x) > 0 else "Unknown")
 
        # Comme nous n'avons pas de v√©ritables Recettes ni votes, on d√©finit ces colonnes sur 0
        df_trans['log_Recettes'] = 0
        df_trans['weighted_rating'] = 0
 
        # Gestion du budget et cr√©ation d'interactions
        df_trans.loc[df_trans['Budget'] == 1.0, 'Budget'] = 0
        df_trans['is_blockbuster'] = (df_trans['Budget'] >= 50000000).astype(int)
        df_trans['actors_weighted_avg'] = df_trans['Actors'].apply(lambda x: actor_map.get(x, 0))
        df_trans['actors_budget_interaction'] = df_trans['actors_weighted_avg'] * df_trans['Budget']
        df_trans['log_Budget'] = np.log1p(df_trans['Budget'])
 
        # Ajout du mapping pour le r√©alisateur
        # on prend la moyenne si le r√©alisateur n'est pas connu
        df_trans["director_weighted_avg"] = df_trans["Director"].apply(lambda x: director_map.get(x, np.mean(list(director_map.values()))))
 
        # On int√®gre la note de popularit√© saisie et on cr√©e la colonne release_year
        df_trans["release_year"] = df_trans["year"]
 
        # Pr√©paration finale : suppression des colonnes non utilis√©es √† l'inf√©rence
        X_new = df_trans.drop(["Recettes", "title", "Budget", "log_Recettes", "weighted_rating"], axis=1)
 
        # S√©paration en variables num√©riques et cat√©gorielles
        X_num = X_new.select_dtypes(include=["float", "int"])
        X_cat = X_new.select_dtypes(include=["object", "category"])
 
        # Encodage safe des variables cat√©gorielles
        for col in X_cat.columns:
            X_cat[col] = X_cat[col].apply(lambda x: safe_label_transform(x, le))
 
        X_new_final = pd.concat([X_num, X_cat], axis=1)
        # R√©indexer pour que l'ordre des colonnes corresponde aux features utilis√©es lors de l'entra√Ænement
        X_new_final = X_new_final.reindex(columns=expected_features)
 
        # Optionnel : affichage interm√©diaire pour v√©rification
        st.write("**Aper√ßu avant scaling**", X_new_final.head())
 
        X_new_scaled = scaler.transform(X_new_final)
        return X_new_scaled
 
    # Chargement du pipeline sauvegard√©
    pipeline = joblib.load("pipeline.joblib")
    print("üîç Cl√©s du pipeline charg√©:", pipeline.keys())
 
    st.write("#### Veuillez saisir les informations du film :")
 
    with st.form("my_form"):
        release_date = st.text_input("Date de sortie (YYYY-MM-DD): ", value="2025-05-10")
        Budget = st.number_input("Budget (en dollars):", min_value=0, value=120000000)
        Director = st.text_input("Nom du r√©alisateur:", value="Christopher Nolan")
        Actors = st.text_input("Liste des acteurs (s√©par√©s par une virgule):", value="Leonardo DiCaprio, Emma Stone")
        Genres_clean = st.text_input("Genre principal:", value="Science Fiction")
        popularity = st.number_input("Note de popularit√© (ex. 5000):", min_value=0.0, value=5000.0)
 
        submitted = st.form_submit_button("Pr√©dire les recettes")
        if submitted:
            data_future = {
                "title": ["Rentrer le titre du film"],
                "release_date": [release_date],
                "Budget": [Budget],
                "Director": [Director],
                "Actors": [Actors],
                "Genres_clean": [Genres_clean],
                "popularity": [popularity]  # On inclut la popularit√© ici
            }
            df_future = pd.DataFrame(data_future)
 
            # Transformation des donn√©es
            X_future = transform_new_data_inference(df_future,
                                                    pipeline["scaler"],
                                                    pipeline["label_encoder"],
                                                    pipeline["director_mapping"],
                                                    pipeline["actor_mapping"],
                                                    pipeline["expected_features"])
 
            prediction = pipeline["model"].predict(X_future)
            st.write("**Pr√©diction (log_Recettes)**:", prediction[0])
            recettes_pred = np.expm1(prediction)
            st.write("**Pr√©diction (Recettes)**:", recettes_pred[0])
 
            # Affichage en millions
            recettes_millions = recettes_pred[0] / 1e6
            st.success(f"Pr√©diction (Recettes) : {recettes_millions:.2f} millions de dollars")
